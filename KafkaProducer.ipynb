{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe2b651-d47b-44b4-9ed8-60b67f7e9df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3811b635-229b-47bf-9f47-16437a326f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kafka-python in d:\\python_projects\\data_engineering\\kafka-stock-market-project-key\\jupyter_env\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: pandas in d:\\python_projects\\data_engineering\\kafka-stock-market-project-key\\jupyter_env\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in d:\\python_projects\\data_engineering\\kafka-stock-market-project-key\\jupyter_env\\lib\\site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\python_projects\\data_engineering\\kafka-stock-market-project-key\\jupyter_env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\python_projects\\data_engineering\\kafka-stock-market-project-key\\jupyter_env\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\python_projects\\data_engineering\\kafka-stock-market-project-key\\jupyter_env\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\python_projects\\data_engineering\\kafka-stock-market-project-key\\jupyter_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Collecting yfinance\n",
      "  Downloading yfinance-0.2.61-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pandas>=1.3.0 in d:\\python_projects\\data_engineering\\kafka-stock-market-project-key\\jupyter_env\\lib\\site-packages (from yfinance) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in d:\\python_projects\\data_engineering\\kafka-stock-market-project-key\\jupyter_env\\lib\\site-packages (from yfinance) (2.2.5)\n",
      "Requirement already satisfied: requests>=2.31 in d:\\python_projects\\data_engineering\\kafka-stock-market-project-key\\jupyter_env\\lib\\site-packages (from yfinance) (2.32.3)\n",
      "Collecting multitasking>=0.0.7 (from yfinance)\n",
      "  Downloading multitasking-0.0.11-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in d:\\python_projects\\data_engineering\\kafka-stock-market-project-key\\jupyter_env\\lib\\site-packages (from yfinance) (4.3.8)\n",
      "Requirement already satisfied: pytz>=2022.5 in d:\\python_projects\\data_engineering\\kafka-stock-market-project-key\\jupyter_env\\lib\\site-packages (from yfinance) (2025.2)\n",
      "Collecting frozendict>=2.3.4 (from yfinance)\n",
      "  Downloading frozendict-2.4.6-py311-none-any.whl.metadata (23 kB)\n",
      "Collecting peewee>=3.16.2 (from yfinance)\n",
      "  Downloading peewee-3.18.1.tar.gz (3.0 MB)\n",
      "     ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "     -------------------------------------- - 2.9/3.0 MB 21.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.0/3.0 MB 17.7 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in d:\\python_projects\\data_engineering\\kafka-stock-market-project-key\\jupyter_env\\lib\\site-packages (from yfinance) (4.13.4)\n",
      "Collecting curl_cffi>=0.7 (from yfinance)\n",
      "  Downloading curl_cffi-0.11.1-cp39-abi3-win_amd64.whl.metadata (15 kB)\n",
      "Collecting protobuf>=3.19.0 (from yfinance)\n",
      "  Downloading protobuf-6.31.0-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting websockets>=13.0 (from yfinance)\n",
      "  Downloading websockets-15.0.1-cp311-cp311-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\python_projects\\data_engineering\\kafka-stock-market-project-key\\jupyter_env\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in d:\\python_projects\\data_engineering\\kafka-stock-market-project-key\\jupyter_env\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (4.13.2)\n",
      "Requirement already satisfied: cffi>=1.12.0 in d:\\python_projects\\data_engineering\\kafka-stock-market-project-key\\jupyter_env\\lib\\site-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in d:\\python_projects\\data_engineering\\kafka-stock-market-project-key\\jupyter_env\\lib\\site-packages (from curl_cffi>=0.7->yfinance) (2025.4.26)\n",
      "Requirement already satisfied: pycparser in d:\\python_projects\\data_engineering\\kafka-stock-market-project-key\\jupyter_env\\lib\\site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\python_projects\\data_engineering\\kafka-stock-market-project-key\\jupyter_env\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\python_projects\\data_engineering\\kafka-stock-market-project-key\\jupyter_env\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\python_projects\\data_engineering\\kafka-stock-market-project-key\\jupyter_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\python_projects\\data_engineering\\kafka-stock-market-project-key\\jupyter_env\\lib\\site-packages (from requests>=2.31->yfinance) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\python_projects\\data_engineering\\kafka-stock-market-project-key\\jupyter_env\\lib\\site-packages (from requests>=2.31->yfinance) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\python_projects\\data_engineering\\kafka-stock-market-project-key\\jupyter_env\\lib\\site-packages (from requests>=2.31->yfinance) (2.4.0)\n",
      "Downloading yfinance-0.2.61-py2.py3-none-any.whl (117 kB)\n",
      "Downloading curl_cffi-0.11.1-cp39-abi3-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 18.3 MB/s eta 0:00:00\n",
      "Downloading frozendict-2.4.6-py311-none-any.whl (16 kB)\n",
      "Downloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
      "Downloading protobuf-6.31.0-cp310-abi3-win_amd64.whl (435 kB)\n",
      "Downloading websockets-15.0.1-cp311-cp311-win_amd64.whl (176 kB)\n",
      "Building wheels for collected packages: peewee\n",
      "  Building wheel for peewee (pyproject.toml): started\n",
      "  Building wheel for peewee (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for peewee: filename=peewee-3.18.1-py3-none-any.whl size=139100 sha256=d1835cbb34f746bf6ab86871897ec2655aa7620b000812e734e7fa4e945a5791\n",
      "  Stored in directory: c:\\users\\arulk\\appdata\\local\\pip\\cache\\wheels\\25\\cb\\79\\a133a0d1d75f318a96614ed7fb97bdf2f35a7b6c4d4e426e3f\n",
      "Successfully built peewee\n",
      "Installing collected packages: peewee, multitasking, websockets, protobuf, frozendict, curl_cffi, yfinance\n",
      "\n",
      "   ---------------------------------------- 0/7 [peewee]\n",
      "   ----- ---------------------------------- 1/7 [multitasking]\n",
      "   ----------- ---------------------------- 2/7 [websockets]\n",
      "   ----------------- ---------------------- 3/7 [protobuf]\n",
      "   ----------------- ---------------------- 3/7 [protobuf]\n",
      "   ----------------- ---------------------- 3/7 [protobuf]\n",
      "   ---------------------------- ----------- 5/7 [curl_cffi]\n",
      "   ---------------------------------- ----- 6/7 [yfinance]\n",
      "   ---------------------------------------- 7/7 [yfinance]\n",
      "\n",
      "Successfully installed curl_cffi-0.11.1 frozendict-2.4.6 multitasking-0.0.11 peewee-3.18.1 protobuf-6.31.0 websockets-15.0.1 yfinance-0.2.61\n"
     ]
    }
   ],
   "source": [
    "!pip install kafka-python\n",
    "!pip install pandas\n",
    "!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb53da3d-4dd9-4e2d-95df-e5b844fe3eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from kafka import KafkaConsumer, KafkaProducer\n",
    "from time import sleep\n",
    "from json import dumps\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60daca0f-b92d-42d6-8a16-251b58e723a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers=['43.205.231.111:9092'], #change ip here\n",
    "                         value_serializer=lambda x: \n",
    "                         dumps(x).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94994d65-0a1b-4b4b-a5a2-592a40bdcc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent: {'message': 'Hello World'}\n",
      "Sent: {'message': 'Hello World'}\n",
      "Sent: {'message': 'Hello World'}\n",
      "Sent: {'message': 'Hello World'}\n",
      "Sent: {'message': 'Hello World'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    message = {\"message\": \"Hello World\"}\n",
    "    producer.send('demo_testing1', value=message)\n",
    "    print(f\"Sent: {message}\")\n",
    "    time.sleep(1)  # Optional: wait a bit between messages\n",
    "\n",
    "producer.flush()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7469d57-ddee-4eef-9a87-8919b355500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'D:\\Python_Projects\\DATA_ENGINEERING\\kafka-stock-market-project-key\\indexProcessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4399c10b-6d4b-4455-9d47-2c47ae358d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>CloseUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HSI</td>\n",
       "      <td>1986-12-31</td>\n",
       "      <td>2568.300049</td>\n",
       "      <td>2568.300049</td>\n",
       "      <td>2568.300049</td>\n",
       "      <td>2568.300049</td>\n",
       "      <td>2568.300049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>333.879006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HSI</td>\n",
       "      <td>1987-01-02</td>\n",
       "      <td>2540.100098</td>\n",
       "      <td>2540.100098</td>\n",
       "      <td>2540.100098</td>\n",
       "      <td>2540.100098</td>\n",
       "      <td>2540.100098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>330.213013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HSI</td>\n",
       "      <td>1987-01-05</td>\n",
       "      <td>2552.399902</td>\n",
       "      <td>2552.399902</td>\n",
       "      <td>2552.399902</td>\n",
       "      <td>2552.399902</td>\n",
       "      <td>2552.399902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>331.811987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HSI</td>\n",
       "      <td>1987-01-06</td>\n",
       "      <td>2583.899902</td>\n",
       "      <td>2583.899902</td>\n",
       "      <td>2583.899902</td>\n",
       "      <td>2583.899902</td>\n",
       "      <td>2583.899902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>335.906987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HSI</td>\n",
       "      <td>1987-01-07</td>\n",
       "      <td>2607.100098</td>\n",
       "      <td>2607.100098</td>\n",
       "      <td>2607.100098</td>\n",
       "      <td>2607.100098</td>\n",
       "      <td>2607.100098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>338.923013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Index        Date         Open         High          Low        Close  \\\n",
       "0   HSI  1986-12-31  2568.300049  2568.300049  2568.300049  2568.300049   \n",
       "1   HSI  1987-01-02  2540.100098  2540.100098  2540.100098  2540.100098   \n",
       "2   HSI  1987-01-05  2552.399902  2552.399902  2552.399902  2552.399902   \n",
       "3   HSI  1987-01-06  2583.899902  2583.899902  2583.899902  2583.899902   \n",
       "4   HSI  1987-01-07  2607.100098  2607.100098  2607.100098  2607.100098   \n",
       "\n",
       "     Adj Close  Volume    CloseUSD  \n",
       "0  2568.300049     0.0  333.879006  \n",
       "1  2540.100098     0.0  330.213013  \n",
       "2  2552.399902     0.0  331.811987  \n",
       "3  2583.899902     0.0  335.906987  \n",
       "4  2607.100098     0.0  338.923013  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33ab5cfd-f3b5-4f4c-87f4-3e5e91bd2904",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m      2\u001b[39m     dict_stock=df.sample(\u001b[32m1\u001b[39m).to_dict(orient=\u001b[33m\"\u001b[39m\u001b[33mrecords\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m#data frame to dictionary format\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mproducer\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdemo_testing1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdict_stock\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Python_Projects\\DATA_ENGINEERING\\kafka-stock-market-project-key\\jupyter_env\\Lib\\site-packages\\kafka\\producer\\kafka.py:878\u001b[39m, in \u001b[36mKafkaProducer.send\u001b[39m\u001b[34m(self, topic, value, key, headers, partition, timestamp_ms)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_is_full \u001b[38;5;129;01mor\u001b[39;00m new_batch_created:\n\u001b[32m    876\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m: Waking up the sender since \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m is either full or\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    877\u001b[39m               \u001b[33m\"\u001b[39m\u001b[33m getting a new batch\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m), tp)\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sender\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwakeup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m future\n\u001b[32m    881\u001b[39m \u001b[38;5;66;03m# handling exceptions and record the errors;\u001b[39;00m\n\u001b[32m    882\u001b[39m \u001b[38;5;66;03m# for API exceptions return them in the future,\u001b[39;00m\n\u001b[32m    883\u001b[39m \u001b[38;5;66;03m# for other exceptions raise directly\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Python_Projects\\DATA_ENGINEERING\\kafka-stock-market-project-key\\jupyter_env\\Lib\\site-packages\\kafka\\producer\\sender.py:586\u001b[39m, in \u001b[36mSender.wakeup\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    584\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    585\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Wake up the selector associated with this send thread.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m586\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwakeup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Python_Projects\\DATA_ENGINEERING\\kafka-stock-market-project-key\\jupyter_env\\Lib\\site-packages\\kafka\\client_async.py:1118\u001b[39m, in \u001b[36mKafkaClient.wakeup\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1116\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wake_lock:\n\u001b[32m   1117\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1118\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wake_w\u001b[49m\u001b[43m.\u001b[49m\u001b[43msendall\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mx\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1119\u001b[39m         \u001b[38;5;28mself\u001b[39m._waking = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1120\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m socket.timeout \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    dict_stock=df.sample(1).to_dict(orient=\"records\")[0]  #data frame to dictionary format\n",
    "    producer.send('demo_testing1', value=dict_stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4066d013-f3ef-412c-91b1-7a2d5d09e289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent: {'Index': 'N225', 'Date': '1989-06-09', 'Open': 33755.69141, 'High': 33812.23047, 'Low': 33581.48828, 'Close': 33639.98047, 'Adj Close': 33639.98047, 'Volume': 0.0, 'CloseUSD': 336.3998047}\n",
      "Sent: {'Index': 'TWII', 'Date': '2021-03-10', 'Open': 15921.4502, 'High': 15986.07031, 'Low': 15857.32031, 'Close': 15911.66992, 'Adj Close': 15911.66992, 'Volume': 4340600.0, 'CloseUSD': 636.4667968}\n",
      "Sent: {'Index': 'N225', 'Date': '1994-03-11', 'Open': 20109.91016, 'High': 20256.23047, 'Low': 20017.09961, 'Close': 20115.31055, 'Adj Close': 20115.31055, 'Volume': 0.0, 'CloseUSD': 201.1531055}\n",
      "Sent: {'Index': 'SSMI', 'Date': '1995-06-08', 'Open': 2819.899902, 'High': 2832.800049, 'Low': 2801.399902, 'Close': 2806.800049, 'Adj Close': 2806.800049, 'Volume': 0.0, 'CloseUSD': 3115.5480543900003}\n",
      "Sent: {'Index': 'IXIC', 'Date': '2013-03-12', 'Open': 3244.850098, 'High': 3249.780029, 'Low': 3229.919922, 'Close': 3242.320068, 'Adj Close': 3242.320068, 'Volume': 1673740000.0, 'CloseUSD': 3242.320068}\n",
      "Sent: {'Index': 'TWII', 'Date': '2004-06-25', 'Open': 5767.379883, 'High': 5827.970215, 'Low': 5753.509766, 'Close': 5802.549805, 'Adj Close': 5802.528809, 'Volume': 3436800.0, 'CloseUSD': 232.1019922}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m producer.flush()  \u001b[38;5;66;03m# Ensure the message is sent immediately\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSent: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdict_stock\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# Optional logging\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Add a small delay to simulate real-time data\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#final code\n",
    "import pandas as pd\n",
    "from kafka import KafkaProducer\n",
    "from time import sleep\n",
    "from json import dumps\n",
    "import json\n",
    "\n",
    "# Create Kafka producer\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=['13.233.92.65:9092'],  # Replace with your broker IP\n",
    "    value_serializer=lambda x: dumps(x).encode('utf-8')  # Serialize dict to JSON bytes\n",
    ")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r'D:\\Python_Projects\\DATA_ENGINEERING\\kafka-stock-market-project-key\\indexProcessed.csv')\n",
    "\n",
    "# Send data to Kafka topic continuously\n",
    "while True:\n",
    "    # Pick one random row from dataframe\n",
    "    dict_stock = df.sample(1).to_dict(orient=\"records\")[0]\n",
    "    \n",
    "    # Send the row to Kafka topic\n",
    "    producer.send('demo_testing1', value=dict_stock)\n",
    "    producer.flush()  # Ensure the message is sent immediately\n",
    "    \n",
    "    print(f\"Sent: {dict_stock}\")  # Optional logging\n",
    "    sleep(1)  # Add a small delay to simulate real-time data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e00030dd-d88e-4bf1-914c-14eaaf52599c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent: {\"('Index', '')\": 'HSI', \"('Date', '')\": '31-12-1986', \"('Open', '^HSI')\": 2568.300048828125, \"('High', '^HSI')\": 2568.300048828125, \"('Low', '^HSI')\": 2568.300048828125, \"('Close', '^HSI')\": 2568.300048828125, \"('Adj Close', '^HSI')\": 2568.300048828125, \"('Volume', '^HSI')\": 0, \"('CloseUSD', '')\": 333.8790063476563}\n",
      "Sent: {\"('Index', '')\": 'HSI', \"('Date', '')\": '02-01-1987', \"('Open', '^HSI')\": 2540.10009765625, \"('High', '^HSI')\": 2540.10009765625, \"('Low', '^HSI')\": 2540.10009765625, \"('Close', '^HSI')\": 2540.10009765625, \"('Adj Close', '^HSI')\": 2540.10009765625, \"('Volume', '^HSI')\": 0, \"('CloseUSD', '')\": 330.2130126953125}\n",
      "✅ All records sent to Kafka.\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from kafka import KafkaProducer\n",
    "from json import dumps\n",
    "from time import sleep\n",
    "\n",
    "# === Step 1: Fetch Historical Stock Data ===\n",
    "data = yf.download('^HSI', start='1986-12-31', end='1987-01-05', auto_adjust=False)\n",
    "\n",
    "# Reset index to make 'Date' a column\n",
    "data.reset_index(inplace=True)\n",
    "data['Index'] = 'HSI'\n",
    "\n",
    "# Fill missing values\n",
    "data['Volume'] = data['Volume'].fillna(0).astype(int)\n",
    "data['Adj Close'] = data['Adj Close'].fillna(data['Close'])\n",
    "\n",
    "# Compute CloseUSD (e.g., 1 HKD = 0.13 USD)\n",
    "data['CloseUSD'] = data['Close'] * 0.13\n",
    "\n",
    "# Format Date\n",
    "data['Date'] = data['Date'].dt.strftime('%d-%m-%Y')\n",
    "\n",
    "# Reorder columns\n",
    "data = data[['Index', 'Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'CloseUSD']]\n",
    "\n",
    "# Flatten column names to avoid tuple key issues\n",
    "data.columns = data.columns.map(str)\n",
    "\n",
    "# === Step 2: Kafka Producer ===\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=['13.233.92.65:9092'],\n",
    "    value_serializer=lambda x: dumps(x).encode('utf-8')\n",
    ")\n",
    "\n",
    "# === Step 3: Send to Kafka Topic ===\n",
    "for _, row in data.iterrows():\n",
    "    message = row.to_dict()\n",
    "    producer.send('demo_testing1', value=message)\n",
    "    producer.flush()\n",
    "    print(f\"Sent: {message}\")\n",
    "    sleep(1)\n",
    "\n",
    "print(\"✅ All records sent to Kafka.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdf42949-f390-41e9-8ed1-ba3fe64a97f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent: {'Index': 'HSI', 'Date': '31-12-1986', 'Open': 2568.300048828125, 'High': 2568.300048828125, 'Low': 2568.300048828125, 'Close': 2568.300048828125, 'Adj Close': 2568.300048828125, 'Volume': 0, 'CloseUSD': 333.8790063476563}\n",
      "Sent: {'Index': 'HSI', 'Date': '02-01-1987', 'Open': 2540.10009765625, 'High': 2540.10009765625, 'Low': 2540.10009765625, 'Close': 2540.10009765625, 'Adj Close': 2540.10009765625, 'Volume': 0, 'CloseUSD': 330.2130126953125}\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from kafka import KafkaProducer\n",
    "from json import dumps\n",
    "from time import sleep\n",
    "\n",
    "# === Step 1: Download Data ===\n",
    "ticker = '^HSI'\n",
    "data = yf.download(ticker, start='1986-12-31', end='1987-01-05', auto_adjust=False)\n",
    "\n",
    "# === Step 2: Reset Index to make 'Date' a column ===\n",
    "data.reset_index(inplace=True)\n",
    "data['Index'] = 'HSI'\n",
    "\n",
    "# === Step 3: Flatten MultiIndex Columns ===\n",
    "if isinstance(data.columns, pd.MultiIndex):\n",
    "    data.columns = [col[0] if isinstance(col, tuple) else col for col in data.columns]\n",
    "\n",
    "# === Step 4: Clean and Arrange Columns ===\n",
    "data['Volume'] = data['Volume'].fillna(0).astype(int)\n",
    "data['Adj Close'] = data['Adj Close'].fillna(data['Close'])\n",
    "data['CloseUSD'] = data['Close'] * 0.13\n",
    "data['Date'] = pd.to_datetime(data['Date']).dt.strftime('%d-%m-%Y')\n",
    "\n",
    "# Final column order\n",
    "data = data[['Index', 'Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'CloseUSD']]\n",
    "\n",
    "# === Step 5: Kafka Producer ===\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=['13.233.92.65:9092'],  # Your Kafka broker IP\n",
    "    value_serializer=lambda x: dumps(x).encode('utf-8')\n",
    ")\n",
    "\n",
    "# === Step 6: Send Each Record to Kafka ===\n",
    "for _, row in data.iterrows():\n",
    "    message = row.to_dict()\n",
    "    producer.send('demo_testing1', value=message)\n",
    "    producer.flush()\n",
    "    print(f\"Sent: {message}\")\n",
    "    sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40c26f07-2551-447a-810f-7fa145cad395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Kafka Producer started. Streaming data... Press Ctrl+C to stop.\n",
      "Sent: {'Index': 'HSI', 'Date': '31-12-1986', 'Open': 2568.300048828125, 'High': 2568.300048828125, 'Low': 2568.300048828125, 'Close': 2568.300048828125, 'Adj Close': 2568.300048828125, 'Volume': 0, 'CloseUSD': 333.8790063476563}\n",
      "Sent: {'Index': 'HSI', 'Date': '02-01-1987', 'Open': 2540.10009765625, 'High': 2540.10009765625, 'Low': 2540.10009765625, 'Close': 2540.10009765625, 'Adj Close': 2540.10009765625, 'Volume': 0, 'CloseUSD': 330.2130126953125}\n",
      "Sent: {'Index': 'HSI', 'Date': '31-12-1986', 'Open': 2568.300048828125, 'High': 2568.300048828125, 'Low': 2568.300048828125, 'Close': 2568.300048828125, 'Adj Close': 2568.300048828125, 'Volume': 0, 'CloseUSD': 333.8790063476563}\n",
      "Sent: {'Index': 'HSI', 'Date': '02-01-1987', 'Open': 2540.10009765625, 'High': 2540.10009765625, 'Low': 2540.10009765625, 'Close': 2540.10009765625, 'Adj Close': 2540.10009765625, 'Volume': 0, 'CloseUSD': 330.2130126953125}\n",
      "Sent: {'Index': 'HSI', 'Date': '31-12-1986', 'Open': 2568.300048828125, 'High': 2568.300048828125, 'Low': 2568.300048828125, 'Close': 2568.300048828125, 'Adj Close': 2568.300048828125, 'Volume': 0, 'CloseUSD': 333.8790063476563}\n",
      "Sent: {'Index': 'HSI', 'Date': '02-01-1987', 'Open': 2540.10009765625, 'High': 2540.10009765625, 'Low': 2540.10009765625, 'Close': 2540.10009765625, 'Adj Close': 2540.10009765625, 'Volume': 0, 'CloseUSD': 330.2130126953125}\n",
      "Sent: {'Index': 'HSI', 'Date': '31-12-1986', 'Open': 2568.300048828125, 'High': 2568.300048828125, 'Low': 2568.300048828125, 'Close': 2568.300048828125, 'Adj Close': 2568.300048828125, 'Volume': 0, 'CloseUSD': 333.8790063476563}\n",
      "Sent: {'Index': 'HSI', 'Date': '02-01-1987', 'Open': 2540.10009765625, 'High': 2540.10009765625, 'Low': 2540.10009765625, 'Close': 2540.10009765625, 'Adj Close': 2540.10009765625, 'Volume': 0, 'CloseUSD': 330.2130126953125}\n",
      "Sent: {'Index': 'HSI', 'Date': '31-12-1986', 'Open': 2568.300048828125, 'High': 2568.300048828125, 'Low': 2568.300048828125, 'Close': 2568.300048828125, 'Adj Close': 2568.300048828125, 'Volume': 0, 'CloseUSD': 333.8790063476563}\n",
      "Sent: {'Index': 'HSI', 'Date': '02-01-1987', 'Open': 2540.10009765625, 'High': 2540.10009765625, 'Low': 2540.10009765625, 'Close': 2540.10009765625, 'Adj Close': 2540.10009765625, 'Volume': 0, 'CloseUSD': 330.2130126953125}\n",
      "Sent: {'Index': 'HSI', 'Date': '31-12-1986', 'Open': 2568.300048828125, 'High': 2568.300048828125, 'Low': 2568.300048828125, 'Close': 2568.300048828125, 'Adj Close': 2568.300048828125, 'Volume': 0, 'CloseUSD': 333.8790063476563}\n",
      "Sent: {'Index': 'HSI', 'Date': '02-01-1987', 'Open': 2540.10009765625, 'High': 2540.10009765625, 'Low': 2540.10009765625, 'Close': 2540.10009765625, 'Adj Close': 2540.10009765625, 'Volume': 0, 'CloseUSD': 330.2130126953125}\n",
      "🛑 Stopped by user.\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from kafka import KafkaProducer\n",
    "from time import sleep\n",
    "from json import dumps\n",
    "\n",
    "# Step 1: Fetch historical stock data\n",
    "ticker = '^HSI'\n",
    "data = yf.download(ticker, start='1986-12-31', end='1987-01-05', auto_adjust=False)\n",
    "\n",
    "# Step 2: Flatten MultiIndex columns if they exist\n",
    "data.columns = [col[0] if isinstance(col, tuple) else col for col in data.columns]\n",
    "\n",
    "# Step 3: Format and enrich data\n",
    "data.reset_index(inplace=True)\n",
    "data['Date'] = data['Date'].dt.strftime('%d-%m-%Y')\n",
    "data['Index'] = 'HSI'\n",
    "data['CloseUSD'] = data['Close'] * 0.13\n",
    "data['Volume'] = data['Volume'].fillna(0).astype(int)\n",
    "\n",
    "# Reorder columns\n",
    "data = data[['Index', 'Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'CloseUSD']]\n",
    "\n",
    "# Step 4: Create Kafka producer\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=['13.233.92.65:9092'],  # Replace with your Kafka IP\n",
    "    value_serializer=lambda x: dumps(x).encode('utf-8')\n",
    ")\n",
    "\n",
    "# Step 5: Stream data to Kafka until manually stopped\n",
    "print(\"✅ Kafka Producer started. Streaming data... Press Ctrl+C to stop.\")\n",
    "try:\n",
    "    while True:\n",
    "        for _, row in data.iterrows():\n",
    "            producer.send('demo_testing1', value=row.to_dict())\n",
    "            producer.flush()\n",
    "            print(f\"Sent: {row.to_dict()}\")\n",
    "            sleep(1)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"🛑 Stopped by user.\")\n",
    "finally:\n",
    "    producer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbb90c6-6bb2-4996-8ab0-333e7bee2691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a2df12-d254-4767-972c-16a0d18441a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
